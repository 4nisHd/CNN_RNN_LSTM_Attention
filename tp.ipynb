{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparative Analysis of Recurrent and Convolutional Models for Sequential Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook made as an assignement for ENSI deep learning class provides a comparative analysis in terms of performance of Convolutional Neural Networks (CNNs), Recurrent Neural Networks (RNNs) and the Long Short-Term Memory (LSTMs) variant of RNNs when applied to sequential data. \n",
    "\n",
    "Both RNNs, including LSTMs, and CNNs have become popular choices for modeling sequential data due to their unique strengths in handling temporal dependencies and efficient feature extraction, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "importing libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Embedding, SimpleRNN, LSTM, Activation\n",
    "from tensorflow.keras.layers import Bidirectional, Input, Layer\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, GlobalMaxPooling1D, Dropout, Dense, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import concurrent.futures\n",
    "from tensorflow.keras.metrics import Precision, Recall, AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training locally with tensorflow gpu using an RTX 3050ti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available.\n",
      "GPU name: /physical_device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    print(\"GPU is available.\")\n",
    "    for gpu in gpus:\n",
    "        print(f\"GPU name: {gpu.name}\")\n",
    "else:\n",
    "    print(\"GPU is not available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Nov 11 14:58:38 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.120                Driver Version: 550.120        CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3050 ...    Off |   00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   55C    P0             13W /   60W |      10MiB /   4096MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A      2213      G   /usr/lib/xorg/Xorg                              4MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing text files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(f):\n",
    "    texts = []\n",
    "    labels = []\n",
    "    with open(f, 'r') as f:\n",
    "        for line in f:\n",
    "            label, text = line.split(\" \", 1)\n",
    "            labels.append(int(label.split('__label__')[1])) \n",
    "            texts.append(text.strip())\n",
    "    return texts, np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering the large size of the file, we'll use parallelization for file loading and processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    train_future = executor.submit(load, 'train.ft.txt')\n",
    "    test_future = executor.submit(load, 'test.ft.txt')\n",
    "    \n",
    "    train_texts, train_labels = train_future.result()\n",
    "    test_texts, test_labels = test_future.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "portion_of_texts = train_texts[:100000]\n",
    "\n",
    "tokenizer = Tokenizer(num_words=10000)  # limit vocab to 10k\n",
    "tokenizer.fit_on_texts(portion_of_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tokenizer.texts_to_sequences(train_texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = tokenizer.texts_to_sequences(test_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Padding for 100 as token length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pad_sequences(X_train, maxlen=100)\n",
    "X_test = pad_sequences(X_test, maxlen=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting labels to np arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(train_labels)\n",
    "y_test = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network (CNN) with 100 token length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNNmodel = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First convolutional layer, using conv1D because of the sequential nature of the data (text data)\n",
    "Using batch normalization after the first conv layer for regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anis-houidi/tf/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "CNNmodel.add(Conv1D(64, 5, activation='relu', input_shape=(X_train.shape[1], 1)))\n",
    "CNNmodel.add(BatchNormalization()) \n",
    "#maxPooling\n",
    "CNNmodel.add(MaxPooling1D(2)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "second convolutional layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNNmodel.add(Conv1D(128, 5, activation='relu'))\n",
    "CNNmodel.add(BatchNormalization())  \n",
    "CNNmodel.add(MaxPooling1D(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "third convolutional layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNNmodel.add(Conv1D(256, 3, activation='relu'))\n",
    "CNNmodel.add(BatchNormalization())  # Batch normalization after the third conv layer\n",
    "CNNmodel.add(MaxPooling1D(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "global maxpooling to reduce sequence length (dimentionality reduction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNNmodel.add(GlobalMaxPooling1D())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dropping random neurons at each feedforward pass for regularization/avoiding overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNNmodel.add(Dropout(0.5)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "first fully connected dense layer with batch normalization;\n",
    "these following layers will be responsible for classification from the features and patterns extracted with the convolutional layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNNmodel.add(Dense(64, activation='relu')) \n",
    "CNNmodel.add(BatchNormalization()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "second fully connected dense layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNNmodel.add(Dense(32, activation='relu'))\n",
    "CNNmodel.add(BatchNormalization())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "output layer of dimension 1  (either label 1 or label 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNNmodel.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model architecture + number of paramaters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">44</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">41,088</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_6           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">44</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">98,560</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_7           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_max_pooling1d_1          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1D</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,448</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_8           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_9           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_3 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │           \u001b[38;5;34m384\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_3 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_4 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m44\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │        \u001b[38;5;34m41,088\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_6           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m44\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_4 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_5 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │        \u001b[38;5;34m98,560\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_7           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_5 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_max_pooling1d_1          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalMaxPooling1D\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m16,448\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_8           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_9           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">160,769</span> (628.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m160,769\u001b[0m (628.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">159,681</span> (623.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m159,681\u001b[0m (623.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,088</span> (4.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,088\u001b[0m (4.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "CNNmodel.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compiling + training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNNmodel.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m225000/225000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m325s\u001b[0m 1ms/step - accuracy: 0.4989 - loss: -97668.0000 - val_accuracy: 0.5000 - val_loss: -752095.0625\n",
      "Epoch 2/10\n",
      "\u001b[1m225000/225000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m296s\u001b[0m 1ms/step - accuracy: 0.4991 - loss: -1369769.8750 - val_accuracy: 0.4999 - val_loss: -3638122.5000\n",
      "Epoch 3/10\n",
      "\u001b[1m225000/225000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m301s\u001b[0m 1ms/step - accuracy: 0.4986 - loss: -4328500.0000 - val_accuracy: 0.5000 - val_loss: -6995024.5000\n",
      "Epoch 4/10\n",
      "\u001b[1m225000/225000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m300s\u001b[0m 1ms/step - accuracy: 0.4991 - loss: -9000041.0000 - val_accuracy: 0.5000 - val_loss: -15811513.0000\n",
      "Epoch 5/10\n",
      "\u001b[1m225000/225000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m277s\u001b[0m 1ms/step - accuracy: 0.4984 - loss: -15413522.0000 - val_accuracy: 0.4994 - val_loss: -20603110.0000\n",
      "Epoch 6/10\n",
      "\u001b[1m225000/225000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m273s\u001b[0m 1ms/step - accuracy: 0.4988 - loss: -23553924.0000 - val_accuracy: 0.5000 - val_loss: -32234214.0000\n",
      "Epoch 7/10\n",
      "\u001b[1m225000/225000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m279s\u001b[0m 1ms/step - accuracy: 0.4984 - loss: -33309452.0000 - val_accuracy: 0.4998 - val_loss: -50361872.0000\n",
      "Epoch 8/10\n",
      "\u001b[1m225000/225000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m273s\u001b[0m 1ms/step - accuracy: 0.4981 - loss: -44904824.0000 - val_accuracy: 0.4999 - val_loss: -55781208.0000\n",
      "Epoch 9/10\n",
      "\u001b[1m225000/225000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m282s\u001b[0m 1ms/step - accuracy: 0.4982 - loss: -58533260.0000 - val_accuracy: 0.4959 - val_loss: -60803252.0000\n",
      "Epoch 10/10\n",
      "\u001b[1m225000/225000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m281s\u001b[0m 1ms/step - accuracy: 0.4979 - loss: -74105680.0000 - val_accuracy: 0.4989 - val_loss: -86892048.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7a1413392a50>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CNNmodel.fit(X_train, y_train, epochs=10, batch_size=16, validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12500/12500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 882us/step - accuracy: 0.4951 - loss: -87694512.0000\n",
      "Test Accuracy: 49.89%\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = CNNmodel.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here, we observe a low training and testing accuracy for the CNN model, even with the use of conv1D layers. \n",
    "\n",
    "this suggests that the model may struggle to capture sequential dependencies effectively, as CNNs generally excel at extracting local patterns but can be limited in handling long-term dependencies in sequential data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent neural network with 100 token length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "RNNmodel = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Embedding layer is used to learn dense vector representations of words, mapping each token to a continuous vector space where similar words are closer together. \n",
    "\n",
    "\n",
    "This layer allows the model to automatically learn meaningful word representations during training, capturing semantic relationships and patterns in the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "RNNmodel.add(Embedding(input_dim=10000, output_dim=128, input_length=100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "first recurrent layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "RNNmodel.add(SimpleRNN(64, return_sequences=True, activation='relu'))  # RNN layer with return_sequences=True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "second recurrent layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "RNNmodel.add(SimpleRNN(32, return_sequences=True, activation='relu'))  # Keep return_sequences=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "global 1D max pooling to reduce sequence length to single vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "RNNmodel.add(GlobalMaxPooling1D())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dropout for regularization/avoiding overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "RNNmodel.add(Dropout(0.3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fully connected layers with batch normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "RNNmodel.add(Dense(64, activation='relu'))\n",
    "RNNmodel.add(BatchNormalization())\n",
    "\n",
    "RNNmodel.add(Dense(32, activation='relu'))\n",
    "RNNmodel.add(BatchNormalization())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "output layer for classification 1D = label 1 or label 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "RNNmodel.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compile + train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "RNNmodel.compile(\n",
    "    optimizer=Adam(),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', Precision(), Recall(), AUC()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 2s/step - accuracy: 0.5157 - auc_8: 0.5038 - loss: 0.8301 - precision_8: 0.4764 - recall_8: 0.4858 - val_accuracy: 0.0000e+00 - val_auc_8: 0.0000e+00 - val_loss: 0.7707 - val_precision_8: 0.0000e+00 - val_recall_8: 0.0000e+00\n",
      "Epoch 2/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 0.6241 - auc_8: 0.6561 - loss: 0.6615 - precision_8: 0.5815 - recall_8: 0.6166 - val_accuracy: 0.0000e+00 - val_auc_8: 0.0000e+00 - val_loss: 0.8347 - val_precision_8: 0.0000e+00 - val_recall_8: 0.0000e+00\n",
      "Epoch 3/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - accuracy: 0.6865 - auc_8: 0.7491 - loss: 0.5943 - precision_8: 0.6729 - recall_8: 0.6614 - val_accuracy: 0.0000e+00 - val_auc_8: 0.0000e+00 - val_loss: 0.8944 - val_precision_8: 0.0000e+00 - val_recall_8: 0.0000e+00\n",
      "Epoch 4/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 0.8015 - auc_8: 0.8812 - loss: 0.4701 - precision_8: 0.7604 - recall_8: 0.8035 - val_accuracy: 0.0000e+00 - val_auc_8: 0.0000e+00 - val_loss: 0.9577 - val_precision_8: 0.0000e+00 - val_recall_8: 0.0000e+00\n",
      "Epoch 5/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 0.9054 - auc_8: 0.9559 - loss: 0.3256 - precision_8: 0.8876 - recall_8: 0.9008 - val_accuracy: 0.0000e+00 - val_auc_8: 0.0000e+00 - val_loss: 0.9678 - val_precision_8: 0.0000e+00 - val_recall_8: 0.0000e+00\n",
      "Epoch 6/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 0.9337 - auc_8: 0.9852 - loss: 0.2233 - precision_8: 0.9167 - recall_8: 0.9392 - val_accuracy: 9.0000e-05 - val_auc_8: 0.0000e+00 - val_loss: 0.9605 - val_precision_8: 1.0000 - val_recall_8: 1.7250e-04\n",
      "Epoch 7/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 0.9442 - auc_8: 0.9929 - loss: 0.1583 - precision_8: 0.9169 - recall_8: 0.9616 - val_accuracy: 7.0750e-04 - val_auc_8: 0.0000e+00 - val_loss: 0.9898 - val_precision_8: 1.0000 - val_recall_8: 0.0013\n",
      "Epoch 8/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 0.9785 - auc_8: 0.9981 - loss: 0.1079 - precision_8: 0.9786 - recall_8: 0.9753 - val_accuracy: 0.0017 - val_auc_8: 0.0000e+00 - val_loss: 0.9931 - val_precision_8: 1.0000 - val_recall_8: 0.0034\n",
      "Epoch 9/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 0.9734 - auc_8: 0.9974 - loss: 0.0884 - precision_8: 0.9665 - recall_8: 0.9740 - val_accuracy: 0.0010 - val_auc_8: 0.0000e+00 - val_loss: 1.0697 - val_precision_8: 1.0000 - val_recall_8: 0.0020\n",
      "Epoch 10/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 0.9840 - auc_8: 0.9992 - loss: 0.0700 - precision_8: 0.9796 - recall_8: 0.9868 - val_accuracy: 0.0033 - val_auc_8: 0.0000e+00 - val_loss: 1.1234 - val_precision_8: 1.0000 - val_recall_8: 0.0065\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7e3b8c4c0e00>"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RNNmodel.fit(X_train, y_train, epochs=10, batch_size=64, validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12500/12500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 3ms/step - accuracy: 0.0032 - auc_8: 0.0000e+00 - loss: 1.1248 - precision_8: 0.9999 - recall_8: 0.0064\n",
      "Test Loss: 1.1234\n",
      "Test Accuracy: 0.33%\n",
      "Test Precision: 1.0000\n",
      "Test Recall: 0.0065\n",
      "Test AUC: 0.0000\n"
     ]
    }
   ],
   "source": [
    "metrics = RNNmodel.evaluate(X_test, y_test)\n",
    "\n",
    "print(f\"Test Loss: {metrics[0]:.4f}\")\n",
    "print(f\"Test Accuracy: {metrics[1] * 100:.2f}%\")\n",
    "print(f\"Test Precision: {metrics[2]:.4f}\")\n",
    "print(f\"Test Recall: {metrics[3]:.4f}\")\n",
    "print(f\"Test AUC: {metrics[4]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9816 - auc_8: 1.0000 - loss: 0.3750 - precision_8: 1.0000 - recall_8: 0.9582\n",
      "Train Loss: 0.3809\n",
      "Train Accuracy: 97.90%\n",
      "Train Precision: 1.0000\n",
      "Train Recall: 0.9541\n",
      "Train AUC: 1.0000\n"
     ]
    }
   ],
   "source": [
    "metrics = RNNmodel.evaluate(X_train, y_train)\n",
    "\n",
    "print(f\"Train Loss: {metrics[0]:.4f}\")\n",
    "print(f\"Train Accuracy: {metrics[1] * 100:.2f}%\")\n",
    "print(f\"Train Precision: {metrics[2]:.4f}\")\n",
    "print(f\"Train Recall: {metrics[3]:.4f}\")\n",
    "print(f\"Train AUC: {metrics[4]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despite the overfitting observed here, the clear superiority of recurrence over convolution in handling sequential data, such as text, is evident.   \n",
    "\n",
    "\n",
    "Recurrent models, by maintaining memory of previous time steps, excel at capturing the dependencies , causality and contextual nuances in sequences. This enables them to effectively model the semantic relationships in text, where the order and context of words significantly impact the meaning. In contrast, convolutional models, while effective in certain tasks, struggle to maintain such long-term dependencies, limiting their performance on sequential data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent neural network with 50 token length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "RNN50_model=Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model will follow the same architecture as the previous RNN but with 50 tokens as the input length in the embedding layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embedding layer to learn dense vector representations of tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "RNN50_model.add(Embedding(input_dim=10000, output_dim=128, input_length=50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RNN50_model.add(SimpleRNN(64, return_sequences=True, activation='relu'))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RNN50_model.add(SimpleRNN(32, return_sequences=True, activation='relu'))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "RNN50_model.add(GlobalMaxPooling1D())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "RNN50_model.add(Dropout(0.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "RNN50_model.add(Dense(64, activation='relu'))\n",
    "RNN50_model.add(BatchNormalization())\n",
    "\n",
    "RNN50_model.add(Dense(32, activation='relu'))\n",
    "RNN50_model.add(BatchNormalization())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "RNN50_model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "RNN50_model.compile(\n",
    "    optimizer=Adam(),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', Precision(), Recall(), AUC()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2s/step - accuracy: 0.5002 - auc_10: 0.5070 - loss: 0.8462 - precision_10: 0.4691 - recall_10: 0.5295 - val_accuracy: 1.7500e-05 - val_auc_10: 0.0000e+00 - val_loss: 0.7363 - val_precision_10: 1.0000 - val_recall_10: 2.2500e-05\n",
      "Epoch 2/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 0.5835 - auc_10: 0.6338 - loss: 0.6676 - precision_10: 0.5666 - recall_10: 0.5439 - val_accuracy: 0.1036 - val_auc_10: 0.0000e+00 - val_loss: 0.7030 - val_precision_10: 1.0000 - val_recall_10: 0.2091\n",
      "Epoch 3/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 0.6501 - auc_10: 0.7131 - loss: 0.6167 - precision_10: 0.6317 - recall_10: 0.5958 - val_accuracy: 0.4416 - val_auc_10: 0.0000e+00 - val_loss: 0.6690 - val_precision_10: 1.0000 - val_recall_10: 0.8775\n",
      "Epoch 4/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 0.8182 - auc_10: 0.8913 - loss: 0.4565 - precision_10: 0.8016 - recall_10: 0.7846 - val_accuracy: 0.4439 - val_auc_10: 0.0000e+00 - val_loss: 0.6526 - val_precision_10: 1.0000 - val_recall_10: 0.8797\n",
      "Epoch 5/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 0.8930 - auc_10: 0.9647 - loss: 0.3269 - precision_10: 0.8898 - recall_10: 0.8654 - val_accuracy: 0.2626 - val_auc_10: 0.0000e+00 - val_loss: 0.6948 - val_precision_10: 1.0000 - val_recall_10: 0.5047\n",
      "Epoch 6/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 0.9359 - auc_10: 0.9822 - loss: 0.2281 - precision_10: 0.9466 - recall_10: 0.9082 - val_accuracy: 0.2614 - val_auc_10: 0.0000e+00 - val_loss: 0.6913 - val_precision_10: 1.0000 - val_recall_10: 0.5027\n",
      "Epoch 7/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 0.9637 - auc_10: 0.9947 - loss: 0.1457 - precision_10: 0.9659 - recall_10: 0.9549 - val_accuracy: 0.3390 - val_auc_10: 0.0000e+00 - val_loss: 0.6399 - val_precision_10: 1.0000 - val_recall_10: 0.6589\n",
      "Epoch 8/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 0.9668 - auc_10: 0.9962 - loss: 0.1164 - precision_10: 0.9827 - recall_10: 0.9446 - val_accuracy: 0.2324 - val_auc_10: 0.0000e+00 - val_loss: 0.7143 - val_precision_10: 1.0000 - val_recall_10: 0.4501\n",
      "Epoch 9/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 0.9771 - auc_10: 0.9984 - loss: 0.0884 - precision_10: 0.9729 - recall_10: 0.9769 - val_accuracy: 0.1526 - val_auc_10: 0.0000e+00 - val_loss: 0.8073 - val_precision_10: 1.0000 - val_recall_10: 0.2933\n",
      "Epoch 10/10\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 0.9918 - auc_10: 0.9996 - loss: 0.0609 - precision_10: 0.9987 - recall_10: 0.9842 - val_accuracy: 0.1758 - val_auc_10: 0.0000e+00 - val_loss: 0.8035 - val_precision_10: 1.0000 - val_recall_10: 0.3370\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7e3b96371790>"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RNN50_model.fit(X_train, y_train, epochs=10, batch_size=64, validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12500/12500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 3ms/step - accuracy: 0.1758 - auc_10: 0.0000e+00 - loss: 0.8012 - precision_10: 1.0000 - recall_10: 0.3405\n",
      "Test Loss: 0.8035\n",
      "Test Accuracy: 17.58%\n",
      "Test Precision: 1.0000\n",
      "Test Recall: 0.3370\n",
      "Test AUC: 0.0000\n"
     ]
    }
   ],
   "source": [
    "metrics = RNN50_model.evaluate(X_test, y_test)\n",
    "\n",
    "print(f\"Test Loss: {metrics[0]:.4f}\")\n",
    "print(f\"Test Accuracy: {metrics[1] * 100:.2f}%\")\n",
    "print(f\"Test Precision: {metrics[2]:.4f}\")\n",
    "print(f\"Test Recall: {metrics[3]:.4f}\")\n",
    "print(f\"Test AUC: {metrics[4]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 1.0000 - auc_10: 1.0000 - loss: 0.2919 - precision_10: 1.0000 - recall_10: 1.0000\n",
      "Train Loss: 0.2887\n",
      "Train Accuracy: 100.00%\n",
      "Train Precision: 1.0000\n",
      "Train Recall: 1.0000\n",
      "Train AUC: 1.0000\n"
     ]
    }
   ],
   "source": [
    "metrics = RNN50_model.evaluate(X_train, y_train)\n",
    "\n",
    "print(f\"Train Loss: {metrics[0]:.4f}\")\n",
    "print(f\"Train Accuracy: {metrics[1] * 100:.2f}%\")\n",
    "print(f\"Train Precision: {metrics[2]:.4f}\")\n",
    "print(f\"Train Recall: {metrics[3]:.4f}\")\n",
    "print(f\"Train AUC: {metrics[4]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe here that when the token length is too short, the model overfits and doesn't generalize well to test data. \n",
    "\n",
    "A possible explanation for this is that the model receives insufficient context from the embedding layer to understand the sequence's structure and dependencies. This leads the RNN to focus on learning patterns within smaller sequences, which may not generalize well to unseen data, causing the model to memorize specific details from the training data instead of learning broader, more general patterns.\n",
    "\n",
    " Additionally, if the sequence length is small, the model might still have a large number of parameters relative to the size of the input, this complexity causes the model to learn more specialized patterns during training. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Long Short-Term Memory (LSTM) with 100 tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTMmodel = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embedding layer to learn dense vector representations of tokens. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anis-houidi/tf/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "LSTMmodel.add(Embedding(input_dim=10000, output_dim=128, input_length=100)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM layer with 64 units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1731305522.112654  212521 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2270 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Ti Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "LSTMmodel.add(LSTM(64, return_sequences=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second LSTM layer with 64 units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTMmodel.add(LSTM(64, return_sequences=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No return sequences because the target shape is (32,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropout for regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTMmodel.add(Dropout(0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dense layer with batch normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTMmodel.add(Dense(64, activation='relu'))\n",
    "LSTMmodel.add(BatchNormalization()) \n",
    "LSTMmodel.add(Dense(16, activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTMmodel.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compiling the model with precision, accuracy, recall and AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTMmodel.compile(\n",
    "    optimizer=Adam(),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', Precision(), Recall(), AUC()]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1731305540.081787  214243 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m112500/112500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m977s\u001b[0m 9ms/step - accuracy: 0.4990 - auc: 0.0000e+00 - loss: -43934236.0000 - precision: 1.0000 - recall: 0.9992 - val_accuracy: 0.5000 - val_auc: 0.0000e+00 - val_loss: -632000640.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 2/10\n",
      "\u001b[1m112500/112500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m990s\u001b[0m 9ms/step - accuracy: 0.5001 - auc: 0.0000e+00 - loss: -1300403712.0000 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 0.5000 - val_auc: 0.0000e+00 - val_loss: -4710282752.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 3/10\n",
      "\u001b[1m112500/112500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m993s\u001b[0m 9ms/step - accuracy: 0.5001 - auc: 0.0000e+00 - loss: -6713518592.0000 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 0.5000 - val_auc: 0.0000e+00 - val_loss: -15184941056.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 4/10\n",
      "\u001b[1m112500/112500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m992s\u001b[0m 9ms/step - accuracy: 0.5004 - auc: 0.0000e+00 - loss: -19397036032.0000 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 0.5000 - val_auc: 0.0000e+00 - val_loss: -35001335808.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 5/10\n",
      "\u001b[1m112500/112500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m991s\u001b[0m 9ms/step - accuracy: 0.5001 - auc: 0.0000e+00 - loss: -42473148416.0000 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 0.5000 - val_auc: 0.0000e+00 - val_loss: -69053046784.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 6/10\n",
      "\u001b[1m112500/112500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m990s\u001b[0m 9ms/step - accuracy: 0.5004 - auc: 0.0000e+00 - loss: -78975606784.0000 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 0.5000 - val_auc: 0.0000e+00 - val_loss: -118304980992.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 7/10\n",
      "\u001b[1m112500/112500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m990s\u001b[0m 9ms/step - accuracy: 0.5003 - auc: 0.0000e+00 - loss: -132028964864.0000 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 0.5000 - val_auc: 0.0000e+00 - val_loss: -184096489472.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 8/10\n",
      "\u001b[1m112500/112500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m988s\u001b[0m 9ms/step - accuracy: 0.4995 - auc: 0.0000e+00 - loss: -204873138176.0000 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 0.5000 - val_auc: 0.0000e+00 - val_loss: -273177378816.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 9/10\n",
      "\u001b[1m112500/112500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m988s\u001b[0m 9ms/step - accuracy: 0.4999 - auc: 0.0000e+00 - loss: -300235522048.0000 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 0.5000 - val_auc: 0.0000e+00 - val_loss: -385296695296.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 10/10\n",
      "\u001b[1m112500/112500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m988s\u001b[0m 9ms/step - accuracy: 0.5003 - auc: 0.0000e+00 - loss: -420872257536.0000 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 0.5000 - val_auc: 0.0000e+00 - val_loss: -522382475264.0000 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x742cc2ba2780>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LSTMmodel.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The LSTM performs poorly. Probably due to the low complexity of the model implemented here: one LSTM layer and two dense layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying a different architecture with larger dense layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anis-houidi/tf/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n",
      "I0000 00:00:1731330271.411374  389444 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2270 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Ti Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "lstmmodel2 = Sequential()\n",
    "lstmmodel2.add(Embedding(input_dim=10000, output_dim=50, input_length=100, name='embedding'))\n",
    "lstmmodel2.add(LSTM(64, name='lstm_layer'))\n",
    "lstmmodel2.add(Dense(256, activation='relu', name='FC1'))\n",
    "lstmmodel2.add(Dropout(0.5))\n",
    "lstmmodel2.add(Dense(1, activation='sigmoid', name='out_layer'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstmmodel2.compile(\n",
    "    optimizer=Adam(),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', Precision(), Recall(), AUC()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1731330334.278305  392959 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m112500/112500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m458s\u001b[0m 4ms/step - accuracy: 0.5001 - auc: 0.0000e+00 - loss: -6050813.5000 - precision: 1.0000 - recall: 0.9999 - val_accuracy: 0.5000 - val_auc: 0.0000e+00 - val_loss: -51042264.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 2/10\n",
      "\u001b[1m112500/112500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m456s\u001b[0m 4ms/step - accuracy: 0.5003 - auc: 0.0000e+00 - loss: -80968984.0000 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 0.5000 - val_auc: 0.0000e+00 - val_loss: -197137296.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 3/10\n",
      "\u001b[1m112500/112500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m463s\u001b[0m 4ms/step - accuracy: 0.4997 - auc: 0.0000e+00 - loss: -250828672.0000 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 0.5000 - val_auc: 0.0000e+00 - val_loss: -437737056.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 4/10\n",
      "\u001b[1m112500/112500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m500s\u001b[0m 4ms/step - accuracy: 0.5003 - auc: 0.0000e+00 - loss: -514582528.0000 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 0.5000 - val_auc: 0.0000e+00 - val_loss: -772626176.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 5/10\n",
      "\u001b[1m112500/112500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m490s\u001b[0m 4ms/step - accuracy: 0.5001 - auc: 0.0000e+00 - loss: -873276672.0000 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 0.5000 - val_auc: 0.0000e+00 - val_loss: -1201604352.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 6/10\n",
      "\u001b[1m112500/112500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m426s\u001b[0m 4ms/step - accuracy: 0.5000 - auc: 0.0000e+00 - loss: -1325987072.0000 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 0.5000 - val_auc: 0.0000e+00 - val_loss: -1724872576.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 7/10\n",
      "\u001b[1m 74812/112500\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m2:20\u001b[0m 4ms/step - accuracy: 0.4997 - auc: 0.0000e+00 - loss: -1823182080.0000 - precision: 1.0000 - recall: 1.0000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mlstmmodel2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/tf/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/tf/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:321\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    319\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m    320\u001b[0m logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[0;32m--> 321\u001b[0m \u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_train_batch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/tf/lib/python3.12/site-packages/keras/src/callbacks/callback_list.py:176\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_train_batch_end\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch, logs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_async_train:\n\u001b[0;32m--> 176\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_async_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_on_train_batch_end\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    178\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_on_train_batch_end(batch, logs)\n",
      "File \u001b[0;32m~/tf/lib/python3.12/site-packages/keras/src/callbacks/callback_list.py:114\u001b[0m, in \u001b[0;36mCallbackList._async_dispatch\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m    112\u001b[0m         future\u001b[38;5;241m.\u001b[39mresult()\n\u001b[1;32m    113\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_futures\u001b[38;5;241m.\u001b[39mremove(future)\n\u001b[0;32m--> 114\u001b[0m future \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_executor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubmit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_futures\u001b[38;5;241m.\u001b[39mappend(future)\n",
      "File \u001b[0;32m/usr/lib/python3.12/concurrent/futures/thread.py:175\u001b[0m, in \u001b[0;36mThreadPoolExecutor.submit\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _shutdown:\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcannot schedule new futures after \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    173\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minterpreter shutdown\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 175\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[43m_base\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFuture\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    176\u001b[0m w \u001b[38;5;241m=\u001b[39m _WorkItem(f, fn, args, kwargs)\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_work_queue\u001b[38;5;241m.\u001b[39mput(w)\n",
      "File \u001b[0;32m/usr/lib/python3.12/concurrent/futures/_base.py:328\u001b[0m, in \u001b[0;36mFuture.__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mFuture\u001b[39;00m(\u001b[38;5;28mobject\u001b[39m):\n\u001b[1;32m    326\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Represents the result of an asynchronous computation.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 328\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    329\u001b[0m \u001b[38;5;250m        \u001b[39m\u001b[38;5;124;03m\"\"\"Initializes the future. Should not be called by clients.\"\"\"\u001b[39;00m\n\u001b[1;32m    330\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition \u001b[38;5;241m=\u001b[39m threading\u001b[38;5;241m.\u001b[39mCondition()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lstmmodel2.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus: a Bi-directional LSTM with an Attention Mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_sz = 10000 \n",
    "emb_dim = 100          \n",
    "token_length = 100          \n",
    "num_classes = 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input layer, this layer is required to structure the model and specify the input format for all subsequent layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=(token_length,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anis-houidi/tf/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "x = Embedding(input_dim=vocab_sz, output_dim=emb_dim, input_length=token_length)(inputs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bi-directional LSTM layer\n",
    "\n",
    " processes the sequence in both forward and backward directions using two LSTM layers, then concatenates the outputs from both directions at each time step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Bidirectional(LSTM(64, return_sequences=True))(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention layer\n",
    "\n",
    "\n",
    "this layer lets the model focus on critical parts of the input, improving performance by selectively weighting important words or phrases that contribute to the classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionLayer(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(AttentionLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.W = self.add_weight(name=\"att_W\", shape=(input_shape[-1], input_shape[-1]), initializer=\"random_normal\")\n",
    "        self.b = self.add_weight(name=\"att_b\", shape=(input_shape[-1],), initializer=\"zeros\")\n",
    "        super(AttentionLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        score = tf.nn.tanh(tf.tensordot(inputs, self.W, axes=1) + self.b)\n",
    "        att_wts = tf.nn.softmax(score, axis=1)\n",
    "        context = tf.reduce_sum(att_wts * inputs, axis=1)\n",
    "        return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = AttentionLayer()(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W and b: learnable weights that help the model capture meaningful relationships within the sequence.\n",
    "\n",
    "\n",
    "score: computes an attention score using tanh to introduce non-linearity, allowing more flexible weight learning.\n",
    "\n",
    "\n",
    "att_wts: converts scores to probabilities(weights) across time steps via softmax, where higher weights indicate more importance.\n",
    "\n",
    "\n",
    "context: produces a context vector by summing the LSTM outputs weighted by their importance. this context vector acts as a summary of the sequence, emphasizing relevant parts based on the learned attention weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = Dense(1, activation='sigmoid')(x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "Attention_model = Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "Attention_model.compile(\n",
    "    optimizer=Adam(),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', Precision(), Recall(), AUC()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1731334143.225549  418288 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m112500/112500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1047s\u001b[0m 9ms/step - accuracy: 0.5007 - auc: 0.0000e+00 - loss: -1795.0321 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 0.5000 - val_auc: 0.0000e+00 - val_loss: -7152.3853 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 2/10\n",
      "\u001b[1m112500/112500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1053s\u001b[0m 9ms/step - accuracy: 0.5002 - auc: 0.0000e+00 - loss: -8934.9355 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 0.5000 - val_auc: 0.0000e+00 - val_loss: -14294.3936 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 3/10\n",
      "\u001b[1m112500/112500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1053s\u001b[0m 9ms/step - accuracy: 0.5005 - auc: 0.0000e+00 - loss: -16065.8379 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 0.5000 - val_auc: 0.0000e+00 - val_loss: -21437.0605 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 4/10\n",
      "\u001b[1m112500/112500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1053s\u001b[0m 9ms/step - accuracy: 0.5002 - auc: 0.0000e+00 - loss: -23213.4102 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 0.5000 - val_auc: 0.0000e+00 - val_loss: -28579.0723 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 5/10\n",
      "\u001b[1m112500/112500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1053s\u001b[0m 9ms/step - accuracy: 0.5002 - auc: 0.0000e+00 - loss: -30355.6953 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 0.5000 - val_auc: 0.0000e+00 - val_loss: -35722.4375 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 6/10\n",
      "\u001b[1m112500/112500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1053s\u001b[0m 9ms/step - accuracy: 0.5000 - auc: 0.0000e+00 - loss: -37509.2539 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 0.5000 - val_auc: 0.0000e+00 - val_loss: -42865.7188 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 7/10\n",
      "\u001b[1m112500/112500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1053s\u001b[0m 9ms/step - accuracy: 0.5004 - auc: 0.0000e+00 - loss: -44616.0859 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 0.5000 - val_auc: 0.0000e+00 - val_loss: -50006.4414 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 8/10\n",
      "\u001b[1m112500/112500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1053s\u001b[0m 9ms/step - accuracy: 0.5004 - auc: 0.0000e+00 - loss: -51757.4141 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 0.5000 - val_auc: 0.0000e+00 - val_loss: -57150.4219 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 9/10\n",
      "\u001b[1m112500/112500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1053s\u001b[0m 9ms/step - accuracy: 0.5001 - auc: 0.0000e+00 - loss: -58926.6523 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 0.5000 - val_auc: 0.0000e+00 - val_loss: -64291.7188 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "Epoch 10/10\n",
      "\u001b[1m112500/112500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1052s\u001b[0m 9ms/step - accuracy: 0.5000 - auc: 0.0000e+00 - loss: -66074.6953 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 0.5000 - val_auc: 0.0000e+00 - val_loss: -71418.4141 - val_precision: 1.0000 - val_recall: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7a92181f2300>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Attention_model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
